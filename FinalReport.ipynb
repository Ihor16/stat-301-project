{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Which linear model is best suited for predicting phones' prices?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction (150)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scholars argue that smartphones evolved from luxurious items into necessities (Tanveer et al.). We use them for \"calling and sending messages,\" \"capturing pictures,\" \"socializing,\" etc. They turned from communication tools into daily \"multimedia machines\" (Tanveer et al.).\n",
    "\n",
    "Nevertheless, buying new phones can be challenging and frustrating due to the flood of features they offer (Kobie). To escape this tough choice, consumers often consider only a device's advertised characteristics without inquiring whether the phone price corresponds to them (K. Srujan Raju et al. 773). Hence, they are likely to make an uninformed decision and overpay.\n",
    "\n",
    "Therefore, it is essential to create an effective **model that would predict a phone's market price given the device's set of characteristics**.\n",
    "\n",
    "Thus, **we want to create and analyze several linear regression models and decide which one, if any, can help consumers evaluate whether the phone's proposed price aligns with the competition and is worth paying**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data set and Methods (87)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use a data set containing phones specifications and prices, which scholars scraped from [gadgets360.com](https://www.gadgets360.com/mobiles/best-phones) - an Indian tech news website - and [published](https://www.kaggle.com/datasets/pratikgarai/mobile-phone-specifications-and-prices) in **2022** (Garai). Therefore, the data has **1321** reliable and recent observations.\n",
    "\n",
    "We use the variables presented below, adjusting them this way to ease the investigation:\n",
    "- Rename them from the original data set\n",
    "- Derive `resolution` from another two variables\n",
    "- Convert `price` from Indian Rupee to US Dollar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Variable Name  | Description                                                 |\n",
    "| -------------- | ----------------------------------------------------------- |\n",
    "| `price`        | Phone price in USD                                          |\n",
    "| `battery`      | Battery capacity in mAh                                     |\n",
    "| `screen_size`  | Screen Size in Inches across opposite corners               |\n",
    "| `resolution`   | The resolution of the phone: (width $\\times$ height) / 1000 |\n",
    "| `processor`    | Number of processor cores                                   |\n",
    "| `ram`          | RAM available in phone in GB                                |\n",
    "| `storage`      | Internal Storage of phone in GB                             |\n",
    "| `rear_camera`  | Resolution of rear camera in MP (0 if unavailable)          |\n",
    "| `front_camera` | Resolution of front camera in MP (0 if unavailable)         |\n",
    "| `num_of_sims`  | Number of SIM card slots in phone                           |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To create linear regression models and assess their performance, we perform these steps:\n",
    "\n",
    "#### 1. [Preliminary Analysis](#preliminary_analysis) <a name=\"methods\"></a>\n",
    "- [Reading and wrangling the data](#data_reading)\n",
    "- [Calculating summary statistics](#summary_statistics_calculation)\n",
    "- [Visualizing the correlation between `price` and other variables](#correlation_visualization)\n",
    "\n",
    "#### 2. [Data Preparation](#data_preparation)\n",
    "- [**Splitting the data** into training and testing, **70% being the training set**](#data_splitting)\n",
    "- [Dealing with **multicollinearity** by calculating Variance Inflation Factor (VIF):](#multicollinearity_check)\n",
    "\n",
    "#### 3. [Model creation](#model_creation)\n",
    "- [Building **Full MLR model**](#mlr_full)\n",
    "- [Building **Reduced MLR model**](#mlr_reduced)\n",
    "- [Building **LASSO regression model**](#lasso)\n",
    "\n",
    "#### 4. [Model evaluation](#evaluation):\n",
    "- Assessing the models' performance using **Mean Squared Error (MSE)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [⧋](#methods) Preliminary Analysis (95) <a name=\"preliminary_analysis\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we do the first part from the list above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### [⧋](#methods) Reading and wrangling the data <a name=\"data_reading\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Installing missing packages\n",
    "# https://stackoverflow.com/a/4090208/18184038\n",
    "package_list <- \"psych\"\n",
    "to_install <- package_list[!(package_list %in% installed.packages()[, \"Package\"])]\n",
    "if (length(to_install)) install.packages(to_install)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(!!! change URL to the data set on the main branch)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options(jupyter.plot_mimetypes = \"image/png\")\n",
    "\n",
    "library(tidyverse)\n",
    "library(psych)\n",
    "library(GGally)\n",
    "library(broom)\n",
    "library(car)\n",
    "library(leaps)\n",
    "library(mltools)\n",
    "library(glmnet)\n",
    "library(grid)\n",
    "library(gridExtra)\n",
    "\n",
    "set.seed(7)\n",
    "\n",
    "# Font size for the plots\n",
    "font_size <- 22\n",
    "\n",
    "# Reading the data set from the web\n",
    "url <- \"https://raw.githubusercontent.com/Ihor16/stat-301-project/main/data/specs.csv\"\n",
    "data_raw <- read.csv(url) %>%\n",
    "  as_tibble()\n",
    "\n",
    "# Previewing the raw data set\n",
    "data_raw %>%\n",
    "  head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conversion rate from INR to USD\n",
    "# https://www.forbes.com/advisor/money-transfer/currency-converter/inr-usd/\n",
    "rate <- 0.012282\n",
    "\n",
    "# Renaming the variables and creating a derived variable for `resolution`\n",
    "phone_data <- data_raw %>%\n",
    "  select_if(is.numeric) %>%\n",
    "  select(-X) %>%\n",
    "  rename(\n",
    "    battery = \"Battery.capacity..mAh.\",\n",
    "    screen_size = \"Screen.size..inches.\",\n",
    "    resolution_x = \"Resolution.x\",\n",
    "    resolution_y = \"Resolution.y\",\n",
    "    processor = \"Processor\",\n",
    "    ram = \"RAM..MB.\",\n",
    "    storage = \"Internal.storage..GB.\",\n",
    "    rear_camera = \"Rear.camera\",\n",
    "    front_camera = \"Front.camera\",\n",
    "    num_of_sims = \"Number.of.SIMs\",\n",
    "    price = \"Price\"\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    price = price * rate,\n",
    "    resolution = (resolution_x * resolution_y) / 1000,\n",
    "    ram = ram / 1000\n",
    "  ) %>%\n",
    "  relocate(resolution, .before = resolution_x) %>%\n",
    "  select(-c(resolution_x, resolution_y)) %>%\n",
    "  drop_na() %>%\n",
    "  select(price, everything())\n",
    "\n",
    "# Previewing the wrangled data set\n",
    "phone_data %>%\n",
    "  head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating summary statistics for the data set\n",
    "phone_data %>%\n",
    "  describe() %>%\n",
    "  select(min, mean, median, max, sd)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scholars specify `ram`, `storage`, and `resolution` as the most significant variables influencing a phone's price (Listianingrum et al.). We check if our data reflects this by comparing the correlations of each variable with `price`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating correlation between `price` and every other variable\n",
    "# https://stackoverflow.com/a/45892364/18184038\n",
    "phone_data_corr <- cor(phone_data[-1], phone_data$price) %>%\n",
    "  as.data.frame() %>%\n",
    "  rename(correlation = V1)\n",
    "\n",
    "# Printing the correlations for each variable in descending order\n",
    "phone_data_corr %>%\n",
    "  arrange(desc(correlation))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 7)\n",
    "\n",
    "# Plotting the distribution of calculated correlation coefficients\n",
    "tibble(\n",
    "  correlation = phone_data_corr$correlation,\n",
    "  name = phone_data[-1] %>% colnames()\n",
    ") %>%\n",
    "  ggplot(aes(x = reorder(name, correlation), y = correlation, fill = name)) +\n",
    "  geom_bar(stat = \"identity\") +\n",
    "  labs(\n",
    "    title = \"Correlations of Input Variables with Phone Price\",\n",
    "    x = \"Input Variable\",\n",
    "    y = \"Correlation with Phone Price\"\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    text = element_text(size = font_size)\n",
    "  ) +\n",
    "  coord_flip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**!!! title**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data corresponds to the scholarly claim, so we expect these variables to be present in our best predictive model.\n",
    "\n",
    "However, the correlation coefficients for these variables are below 0.7. Therefore, we need to build linear prediction models to see if this data is suitable for predicting `price` via linear regression."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [⧋](#methods) Data Preparation (277) <a name=\"data_preparation\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### [⧋](#methods) Splitting the Data Set <a name=\"data_splitting\"></a>\n",
    "\n",
    "First, we apply the **holdout method** by splitting the wrangled data into:\n",
    "- Training (70% of the observations)\n",
    "- Testing (30%)\n",
    "\n",
    "We treat the training set as our sample and the testing one as the new data used to evaluate the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adding `ID` column to the full data set\n",
    "phone_data$ID <- rownames(phone_data)\n",
    "\n",
    "# (1) Shuffling the full data set\n",
    "# (2) Selecting 70% of the observations\n",
    "# (3) Assigning those to the training data set\n",
    "phone_training <- phone_data %>%\n",
    "  sample_n(size = nrow(phone_data) * 0.7)\n",
    "\n",
    "# Assigning the rest 30% of the observations to the testing set\n",
    "phone_testing <- anti_join(\n",
    "  x = phone_data,\n",
    "  y = phone_training,\n",
    "  by = \"ID\"\n",
    ")\n",
    "\n",
    "# Dropping the `ID` column from the created data sets\n",
    "phone_training <- phone_training %>%\n",
    "  select(-ID)\n",
    "phone_testing <- phone_testing %>%\n",
    "  select(-ID)\n",
    "\n",
    "# Calculating the number of observations in training and testing sets\n",
    "tibble(\n",
    "  data_set = c(\"training_data\", \"testing_data\"),\n",
    "  num_of_obs = c(phone_training %>% nrow(), phone_testing %>% nrow())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### [⧋](#methods) Multicollinearity Check <a name=\"multicollinearity_check\"></a>\n",
    "\n",
    "Multicollinearity occurs when there's a high correlation between the model's input variables. Therefore, such a model tends to produce invalid predictions because a change in one input variable causes a significant alteration in another (Wu).\n",
    "\n",
    "Thus, we estimate its presence in our data by creating a **correlation heat map** visualizing \"the strength of relationships between numerical variables\" (Kumar)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a correlation matrix for all numerical variables\n",
    "phone_data_corr_matrix <- phone_training %>%\n",
    "  cor() %>%\n",
    "  as.data.frame() %>%\n",
    "  rownames_to_column(\"var1\") %>%\n",
    "  pivot_longer(-var1, names_to = \"var2\", values_to = \"corr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 12)\n",
    "\n",
    "# Creating the heat map plot\n",
    "phone_data_corr_matrix %>%\n",
    "  ggplot(aes(var1, var2)) +\n",
    "  geom_tile(aes(fill = corr), color = \"white\") +\n",
    "  scale_fill_distiller(\n",
    "    \"Correlation coefficient \\n\",\n",
    "    palette = \"Greens\",\n",
    "    direction = 1,\n",
    "    limits = c(-1, 1)\n",
    "  ) +\n",
    "  theme_minimal() +\n",
    "  labs(\n",
    "    title = \"Correlation matrix for all continuous input variables\",\n",
    "    x = \"\", y = \"\") +\n",
    "  theme(\n",
    "    axis.text.x = element_text(\n",
    "      angle = 45, vjust = 1,\n",
    "      size = font_size, hjust = 1\n",
    "    ),\n",
    "    axis.text.y = element_text(\n",
    "      vjust = 1,\n",
    "      size = font_size, hjust = 1\n",
    "    ),\n",
    "    legend.title = element_text(size = font_size, face = \"bold\"),\n",
    "    title = element_text(size = font_size)\n",
    "  ) +\n",
    "  coord_fixed() +\n",
    "  geom_text(aes(x = var1,\n",
    "                y = var2,\n",
    "                label = round(corr, 2)),\n",
    "            color = \"black\",\n",
    "            size = 9\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe these variable pairs with correlation $\\geq$ 0.7:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Variable pair               | Correlation value |\n",
    "| --------------------------- | ----------------- |\n",
    "| `storage` and `ram`         | 0.85              |\n",
    "| `screen_size` and `battery` | 0.75              |\n",
    "| `resolution` and `ram`      | 0.72              |\n",
    "| `screen_size` and `ram`     | 0.71              |\n",
    "| `ram` and `front_camera`    | 0.7               |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now assess the multicollinearity rigorously and find whether the correlations presented above are problematic by creating a function that calculates **VIF**, a measure of \"how much the variance of an independent variable is influenced by its correlation with the other independent variables\" (Potters)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (1) Creates MLR for the `data_set` using `price` as a dependant variable and all the rest as input variables\n",
    "# (2) Calculates the model's VIFs for each input variable and prints the highest 5 of them\n",
    "calculate_vif <- function(data_set) {\n",
    "  # Creating a multiple linear regression for `price` using all input variables from the given data set\n",
    "  mlr <- data_set %>%\n",
    "    lm(formula = price ~ .)\n",
    "\n",
    "  # Using Variance Inflation Factor (VIF) to quantify the possible multicollinearity\n",
    "  mlr %>%\n",
    "    vif() %>%\n",
    "    as.data.frame() %>%\n",
    "    rename(VIF = \".\") %>%\n",
    "    round(3) %>%\n",
    "    arrange(desc(VIF)) %>%\n",
    "    head(5)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we input the training set into this function to see the VIF for each input variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating VIF values using the whole training set\n",
    "calculate_vif(phone_training)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> `ram` and `storage` have the highest VIFs, which we expected because their correlation in the heat map was the highest.\n",
    "\n",
    "Scholars argue that VIF above 10 denotes multicollinearity, while others say values above 5 are also problematic (Bock).\n",
    "\n",
    "Therefore, we try to remedy our **6.18** VIF for `ram` by:\n",
    "- Removing highly correlated variables\n",
    "- Adjusting the `ram` variable and changing its interpretation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating VIFs after dropping `storage`\n",
    "calculate_vif(phone_training %>% select(-storage))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating VIFs after dropping `front_camera`\n",
    "calculate_vif(phone_training %>% select(-front_camera))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Adjusting `ram` column to indicate how much a phone's ram capacity is above average\n",
    "phone_data_adjusted_ram <- phone_training %>%\n",
    "  mutate(ram = ram - 4)\n",
    "\n",
    "# Calculating VIFs after adjusting `ram`\n",
    "calculate_vif(phone_data_adjusted_ram)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VIFs become significantly smaller after we drop `storage`. However, scholars consider this variable significant for predicting a phone's price (Listianingrum et al.), so we keep it as it may give our models more information.\n",
    "\n",
    "Thus, we continue our investigation without changing the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [⧋](#methods) Model Creation (553) <a name=\"model_creation\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [⧋](#methods) MLR Full Model <a name=\"mlr_full\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiple Linear Regression (MLR) is a linear regression that uses multiple input variables to predict a dependent variable. We create an MLR using all input variables to predict `price`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Building predictive Ordinary Least Squares LR model with all input variables\n",
    "phone_model_full <- phone_training %>%\n",
    "  lm(formula = price ~ .)\n",
    "\n",
    "# Displaying the summary statistics of the full MLR model\n",
    "phone_model_full %>%\n",
    "  glance()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the `r.squared` column, which indicates the **coefficient of determination**, we see that the full MLR explains **52.8%** of the variation of the dependent variable `price`. However, this value does not indicate how well our model would predict out-of-sample observations, so we need to evaluate this metric using the testing set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtaining out-of-sample predictions for `price` from the testing set using the full model\n",
    "phone_model_full_test <- predict(\n",
    "  object = phone_model_full,\n",
    "  newdata = phone_testing,\n",
    ")\n",
    "\n",
    "# Displaying a confidence interval for prediction for the full model\n",
    "phone_training %>%\n",
    "  select(ram, storage, screen_size) %>%\n",
    "  cbind(predict(phone_model_full, interval = \"confidence\")) %>%\n",
    "  head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The **95% Confidence Interval for Prediction (CIP)** shown above means that, using the full MLR model, we're 95% certain that the range of **45.01 to 72.94 USD** contains the average price of a phone with `ram` of 1GB, `storage` of 8GB, and `screen_size` of 4.5 inches.\n",
    "\n",
    "Now, we use the testing set again to evaluate the model by calculating its **MSE**, the average squared difference between the prices in the testing set and the predicted prices stored in `phone_model_full_test`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating the MSE value for the full model\n",
    "phone_model_full_rmse <- rmse(\n",
    "  preds = phone_model_full_test,\n",
    "  actuals = phone_testing$price\n",
    ")\n",
    "\n",
    "# Storing full model's MSE in the results tibble\n",
    "phone_rmses <- tibble(\n",
    "  model = \"OLS Full Regression\",\n",
    "  rmse = phone_model_full_rmse\n",
    ")\n",
    "phone_rmses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We aim to use MSE values to compare models' performances, so our value of **114.19** is only helpful if we create another model, calculate its MSE, and compare them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [⧋](#methods) MLR Stepwise Selection Reduced Model <a name=\"mlr_reduced\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we select variables significantly associated with `price` and fit another MLR using those. Using a model with fewer input variables can be beneficial because of these reasons (Rajpurohit):\n",
    "- The model would contain only relevant variables, so it's less likely to have hidden relationships between its predictors\n",
    "- Models with fewer input variables tend to perform well on both training and testing sets because such models avoid overfitting\n",
    "\n",
    "In our analysis, we perform a stepwise variable selection using a **forward selection** algorithm. This algorithm starts with a model containing one input variable. Then it builds other models by sequentially adding variables so that each model is the best for its number of input variables. However, once a variable is selected, it is present in all subsequent models.\n",
    "\n",
    "The last built model contains `nmax` input variables. We set this value to the maximum possible number of predictors, so the rearmost model is the full MLR from above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performing forward variable selection on the training set\n",
    "phone_forward_sel <- regsubsets(\n",
    "  x = price ~ .,\n",
    "  nvmax = ncol(phone_training) - 1,\n",
    "  data = phone_training,\n",
    "  method = \"forward\"\n",
    ")\n",
    "phone_forward_sel\n",
    "\n",
    "# Storing the summary statistics of the variable selection\n",
    "phone_forward_sel_summary <- summary(phone_forward_sel)\n",
    "phone_forward_sel_summary\n",
    "\n",
    "Thus, the most precise model would have the smallest Cp."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Storing variable selection metrics\n",
    "phone_forward_sel_summary_df <- tibble(\n",
    "  n_input_vars = 1:9,\n",
    "  rss = phone_forward_sel_summary$rss,\n",
    "  bic = phone_forward_sel_summary$bic,\n",
    "  cp = phone_forward_sel_summary$cp\n",
    ")\n",
    "phone_forward_sel_summary_df\n",
    "\n",
    "# Saving the row with the smallest Cp value\n",
    "min_cp <- phone_forward_sel_summary_df %>%\n",
    "  filter(cp == min(phone_forward_sel_summary_df$cp))\n",
    "min_cp\n",
    "\n",
    "options(repr.plot.width = 15, repr.plot.height = 7)\n",
    "\n",
    "# Plotting Cp values from the variable selection summary table\n",
    "phone_forward_sel_summary_df %>%\n",
    "  ggplot(aes(x = n_input_vars, y = cp)) +\n",
    "  geom_line() +\n",
    "  geom_point(aes(x = n_input_vars, y = cp), size = 3) +\n",
    "  scale_x_discrete(limits = factor(1:9)) +\n",
    "  geom_point(\n",
    "    data = min_cp,\n",
    "    color = \"red\",\n",
    "    size = 5\n",
    "  ) +\n",
    "  labs(\n",
    "    title = \"Mallows' Cp Statistic vs. Num. of Variables\",\n",
    "    x = \"Num. of variables\",\n",
    "    y = \"Mallows' Cp Statistic\"\n",
    "  ) +\n",
    "  theme(text = element_text(size = font_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The minimum Cp value corresponds to the model with **7** variables, so now we use `phone_forward_sel_summary` to see which variables were selected and build a reduced MLR using them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "phone_forward_sel_summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Building a model using the variables selected by the stepwise forward selection\n",
    "phone_model_stepwise <- phone_training %>%\n",
    "  lm(formula = price ~ battery +\n",
    "    resolution +\n",
    "    processor +\n",
    "    ram +\n",
    "    storage +\n",
    "    front_camera +\n",
    "    num_of_sims\n",
    "  )\n",
    "\n",
    "phone_model_stepwise %>%\n",
    "  glance()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the `r.squared` column, we obtain the coefficient of determination of **52.8%**, the same as for the full MLR. Now, we can build and interpret a CIP from this model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtaining out-of-sample predictions for `price` from the testing set using the stepwise reduced model\n",
    "phone_model_stepwise_test <- predict(\n",
    "  object = phone_model_stepwise,\n",
    "  newdata = phone_testing\n",
    ")\n",
    "\n",
    "# Displaying a confidence interval for prediction for the stepwise reduced model\n",
    "phone_training %>%\n",
    "  select(ram, storage, screen_size) %>%\n",
    "  cbind(predict(phone_model_stepwise,\n",
    "                interval = \"confidence\",\n",
    "                level = 0.95)) %>%\n",
    "  head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The CIP shows that using this model, we're 95% certain that the range of **45.13 to 72.79 USD** contains the average phone price with the presented characteristics. This CIP is similar to the one from the full MLR, which hints that performing the variable selection did not yield significantly different results for our data.\n",
    "\n",
    "However, we now evaluate the reduced model's performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculating the MSE value for the stepwise reduced model\n",
    "phone_model_stepwise_rmse <- rmse(\n",
    "  preds = phone_model_stepwise_test,\n",
    "  actuals = phone_testing$price\n",
    ")\n",
    "\n",
    "# Adding stepwise reduced model's MSE to the results tibble\n",
    "phone_rmses <- phone_rmses %>%\n",
    "  rbind(tibble(\n",
    "    model = \"OLS Stepwise Reduced Regression\",\n",
    "    rmse = phone_model_stepwise_rmse\n",
    "  )) %>%\n",
    "  unique()\n",
    "\n",
    "phone_rmses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LASSO Model\n",
    "\n",
    "We have decided to utilise the Lasso model and think it will be advantageous in the aspects listed below:\n",
    "- **prevent overfitting**\n",
    "- **shrink part of the coefficients to 0, helps with variable selection**\n",
    "\n",
    "To prepare for this model, we first generated four metrics. Two of these are matrices produced from the training set; one is for the entire set of input variables, while the other is just for the response variable. For the testing set, use the same procedure.\n",
    "The MSE for the reduced model is smaller, which means this model is better. We expected this, given that fewer variables are likely to reduce the input variables' collinearity we studied above.\n",
    "\n",
    "Nevertheless, next, we build the LASSO model and evaluate if it is even better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LASSO Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a matrix of all input variables from the training set\n",
    "phone_training_matrix_x <- phone_training %>%\n",
    "  select(-price) %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Creating a matrix of responses from the training set\n",
    "phone_training_matrix_y <- phone_training %>%\n",
    "  select(price) %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Creating a matrix of all input variables from the testing set\n",
    "phone_testing_matrix_x <- phone_testing %>%\n",
    "  select(-price) %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Creating a matrix of responses from the testing set\n",
    "phone_testing_matrix_y <- phone_testing %>%\n",
    "  select(price) %>%\n",
    "  as.matrix()\n",
    "\n",
    "# Finding the optimal value of lambda, the penalty parameter\n",
    "phone_cv_lambda <- cv.glmnet(\n",
    "  x = phone_training_matrix_x,\n",
    "  y = phone_training_matrix_y,\n",
    "  alpha = 1\n",
    ")\n",
    "\n",
    "# Plotting the range of lambda values vs. MSE\n",
    "phone_cv_lambda %>%\n",
    "  plot(\n",
    "    main = \"Lambda selection by Cross Validation with LASSO\\n\\n\"\n",
    "  )\n",
    "\n",
    "# Storing the min value of lambda\n",
    "phone_lambda_min <- round(phone_cv_lambda$lambda.min, 3)\n",
    "\n",
    "# Displaying the min value of lambda\n",
    "round(log(phone_lambda_min), 2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Building LASSO model with the min lambda\n",
    "phone_model_lasso <- glmnet(\n",
    "  x = phone_training_matrix_x,\n",
    "  y = phone_training_matrix_y,\n",
    "  alpha = 1,\n",
    "  lambda = phone_lambda_min\n",
    ")\n",
    "\n",
    "# Comparing coefficients from the full MLR model and LASSO with min lambda\n",
    "data.frame(\n",
    "  full_model = coef(phone_model_full),\n",
    "  lasso = c(phone_model_lasso$a0, as.vector(phone_model_lasso$beta))\n",
    ") %>%\n",
    "  round(3)\n",
    "\n",
    "# Obtaining out-of-sample predictions for `price` from the testing set using the lasso model\n",
    "phone_model_lasso_test <- predict(\n",
    "  object = phone_model_lasso,\n",
    "  newx = phone_testing_matrix_x\n",
    ")\n",
    "\n",
    "# Calculating the MSE value for the lasso model\n",
    "phone_model_lasso_rmse <- rmse(\n",
    "  preds = phone_model_lasso_test,\n",
    "  actuals = phone_testing$price\n",
    ")\n",
    "\n",
    "# Adding LASSO model's MSE to the results tibble\n",
    "phone_rmses <- phone_rmses %>%\n",
    "  rbind(tibble(\n",
    "    model = \"LASSO Regression with min MSE\",\n",
    "    rmse = phone_model_lasso_rmse\n",
    "  )) %>%\n",
    "  unique()\n",
    "\n",
    "phone_rmses %>%\n",
    "  as.data.frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [⧋](#methods) Evaluation (395) <a name=\"evaluation\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our models explain 52.8% of the training set's variation, and the MSE for all of them is approximately the same. Therefore, in our analysis, we made multiple crucial mistakes that prevented us from creating effective regression models.\n",
    "\n",
    "**(1) First**, we did not check for the linearity assumption yet still assumed that our variables are linearly related. However, the scatter plots of `price` vs. each input variable make it evident that most variables are not linearly related to `price`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 10)\n",
    "\n",
    "# Creating scatter plots between all variables\n",
    "plots <- phone_training %>%\n",
    "  ggpairs()\n",
    "\n",
    "# Printing the scatter plots between price and an each input variable\n",
    "grid.arrange(plots[2, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[3, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[4, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[5, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[6, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[7, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[8, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[9, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             plots[10, 1] + coord_flip() + geom_point(size = 3) + theme(text = element_text(size = font_size)),\n",
    "             nrow = 3, ncol = 3,\n",
    "             top = textGrob(\"Price vs. Each Input Variable\",\n",
    "                            gp = gpar(fontsize = font_size + 10))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, it was wrong to use linear regression for modeling their relationship. Future studies may use other methods to fit a predictive model that better captures the relationship between input variables and `price` in this data to fix this mistake.\n",
    "\n",
    "**(2) Second**, as the plot above shows, it could be better to treat `processor`, `ram`, `storage`, and `num_of_sims` as categorical variables rather than continuous. This change would involve adjusting the methodology of selecting significant variables: it would be necessary to use F-tests instead of the forward selection algorithm we applied. Therefore, future studies can try this method and compare their findings.\n",
    "\n",
    "**(3) Third**, we assumed the normality of the residuals for our fitted models. However, their distribution plots below indicate right skewness, which means our models don't explain all trends in the data. One potential remedy that future research can employ is building a model using interaction terms. This addition would cover the cases when, for example, an independent variable `A` influences the `price` differently depending on the values of another independent variable `B` (Interactions in Multiple Linear Regression Basic Ideas)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 10)\n",
    "\n",
    "# Plotting the distributions of residuals for full and reduced MLR models\n",
    "# https://stackoverflow.com/a/10907452/18184038\n",
    "par(mfrow = c(1, 2), cex = 2)\n",
    "hist(residuals(phone_model_full),\n",
    "     main = \"Full MLR Residuals Distribution\")\n",
    "hist(residuals(phone_model_stepwise),\n",
    "     main = \"Reduced MLR Residuals Distribution\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additionally, there are several limitations of the data set, which prevented our analysis from being successful:\n",
    "\n",
    "- Even though the data set was published in 2022, it missed variables describing critical features of modern smartphones. For example, the data did not have variables describing screen refresh rate, availability of NFS module, or 5G compatibility, which may influence smartphone prices today. This lack of input variables can be corrected by re-parsing the website and retrieving these new features.\n",
    "\n",
    "- The data contained smartphone observations from the Indian market, so our study assumed that its prices reflected the global situation. However, it's not always the case. For example, iPhone prices in the US are significantly lower (Hilsenteger). Future studies can fix this limitation by parsing websites from different regions and randomly selecting phones from this international data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! add figure/table numbers\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [⧋](#methods) Conclusion (200)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "“Best Mobile Phones in India | Latest & New Smartphones Price.” *Gadgets 360*, 2020, www.gadgets360.com/mobiles/best-phones. Accessed 3 Dec. 2022.\n",
    "\n",
    "Bock, Tim. “What Are Variance Inflation Factors (VIFs)? | Displayr.com.” *Displayr*, 6 Apr. 2018, www.displayr.com/variance-inflation-factors-vifs/.\n",
    "\n",
    "Garai, Pratik. “Mobile Phone Specifications and Prices.” *Www.kaggle.com*, 14 Aug. 2022, www.kaggle.com/datasets/pratikgarai/mobile-phone-specifications-and-prices. Accessed 4 Dec. 2022.\n",
    "\n",
    "Hilsenteger, Lewis. “IPhone 14 ESIM Controversy Explained.” *Www.youtube.com*, 12 Sept. 2022, www.youtube.com/watch?t=543&v=DLILlKdELEk&feature=youtu.be. Accessed 3 Dec. 2022.\n",
    "\n",
    "K. Srujan Raju, et al. *Data Engineering and Communication Technology*. Springer, 9 Jan. 2020, p. 773.\n",
    "\n",
    "Kobie, Nicole. “Why Does Buying a New Phone Have to Be so - ProQuest.” *Www.proquest.com*, Apr. 2017, www.proquest.com/docview/1985885659?accountid=14656&forcedol=true&pq-origsite=summon. Accessed 3 Dec. 2022.\n",
    "\n",
    "Kumar, Ajitesh. “Correlation Concepts, Matrix & Heatmap Using Seaborn.” *Data Analytics*, 16 Apr. 2022, vitalflux.com/correlation-heatmap-with-seaborn-pandas/#:~:text=with%20each%20other.-.\n",
    "\n",
    "Listianingrum, T, et al. “Smartphone Hedonic Price Study Based on Online Retail Price in Indonesia.” *Journal of Physics: Conference Series*, vol. 1863, no. 1, 1 Mar. 2021, p. 012032, 10.1088/1742-6596/1863/1/012032. Accessed 1 May 2022.\n",
    "\n",
    "Potters, Charles. “Variance Inflation Factor (VIF).” *Investopedia*, 26 July 2022, www.investopedia.com/terms/v/variance-inflation-factor.asp#:~:text=Variance%20inflation%20factor%20measures%20how.\n",
    "\n",
    "Tanveer, Muhammad, et al. “Mobile Phone Buying Decisions among Young Adults: An Empirical Study of Influencing Factors.” *Sustainability*, vol. 13, no. 19, 27 Sept. 2021, p. 10705, 10.3390/su131910705. Accessed 8 Oct. 2021.\n",
    "\n",
    "Wu, Songhao. “Multi-Collinearity in Regression.” *Medium*, 23 May 2020, towardsdatascience.com/multi-collinearity-in-regression-fe7a2c1467ea."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
